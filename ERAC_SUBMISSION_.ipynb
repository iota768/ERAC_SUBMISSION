{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "072d518e",
      "metadata": {
        "id": "072d518e"
      },
      "source": [
        "# 📘 ArIES Research Paper Evaluator\n",
        "Automated publishability assessment, justification generation, and Q&A system."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2bd822f0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bd822f0",
        "outputId": "b6f2570b-22e7-4cc0-f7e2-96ed9055d54f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (1.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.5)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (4.51.3)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (2.6.0+cu124)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (1.14.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (0.30.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from sentence-transformers) (11.1.0)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (2.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.13.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.23)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.11/dist-packages (1.10.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.51)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.28)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.3)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "# ✅ Install Required Packages\n",
        "!pip install sentence-transformers scikit-learn pandas joblib tqdm pymupdf\n",
        "!pip install transformers accelerate\n",
        "!pip install langchain faiss-cpu\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29253a41",
      "metadata": {
        "id": "29253a41"
      },
      "source": [
        "## 📄 Step 1: Extract Text from PDFs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "d478191b",
      "metadata": {
        "id": "d478191b"
      },
      "outputs": [],
      "source": [
        "import fitz  # PyMuPDF\n",
        "\n",
        "def extract_text_from_pdf(pdf_path):\n",
        "    doc = fitz.open(pdf_path)\n",
        "    return \"\\n\".join(page.get_text() for page in doc)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"models\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "pKfPR3bHvBSJ"
      },
      "id": "pKfPR3bHvBSJ",
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "import joblib\n",
        "import os\n",
        "\n",
        "# Sample data\n",
        "X = [\"this is a document\", \"this is another document\", \"text data for classification\"]\n",
        "y = [\"class1\", \"class1\", \"class2\"]\n",
        "\n",
        "# Step 1: Create the model pipeline\n",
        "clf = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer()),\n",
        "    ('nb', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Step 2: Train the model\n",
        "clf.fit(X, y)\n",
        "\n",
        "# Step 3: Save the model\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "joblib.dump(clf, \"models/classifier.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0di2CuS87sq0",
        "outputId": "a1c42562-81aa-4c6b-fce6-3b793039b006"
      },
      "id": "0di2CuS87sq0",
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['models/classifier.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"models\", exist_ok=True)  # ✅ create the folder if it doesn't exist\n",
        "\n",
        "joblib.dump(clf, \"models/classifier.pkl\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGy98IFdvCkm",
        "outputId": "2eba461c-3f70-4467-8e50-0a28043eedec"
      },
      "id": "nGy98IFdvCkm",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['models/classifier.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7eb889b4",
      "metadata": {
        "id": "7eb889b4"
      },
      "source": [
        "## 🧠 Step 2: Train Classifier from 15 Labeled Papers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "06026dc7",
      "metadata": {
        "id": "06026dc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e52fb42-45ca-460b-f004-450e3e97b7b7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.6666666666666666\n",
            "F1 Score: 0.6666666666666666\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['models/classifier.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import joblib\n",
        "\n",
        "df = pd.read_csv(\"data/labels.csv\")\n",
        "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "X, y = [], []\n",
        "for _, row in df.iterrows():\n",
        "    text = extract_text_from_pdf(f\"data/papers/{row['filename']}\")\n",
        "    embedding = embedder.encode(text)\n",
        "    X.append(embedding)\n",
        "    y.append(1 if row['label'] == \"Publishable\" else 0)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "clf = RandomForestClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
        "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
        "\n",
        "joblib.dump(clf, \"models/classifier.pkl\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data/papers\n"
      ],
      "metadata": {
        "id": "3iTtEpv1uRQ3"
      },
      "id": "3iTtEpv1uRQ3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fpdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-vKLgcLuTCl",
        "outputId": "0c29381e-243e-4a27-d4c8-d3eaac7de432"
      },
      "id": "M-vKLgcLuTCl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fpdf in /usr/local/lib/python3.11/dist-packages (1.7.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from fpdf import FPDF\n",
        "\n",
        "def create_dummy_pdf(filename, text):\n",
        "    pdf = FPDF()\n",
        "    pdf.add_page()\n",
        "    pdf.set_font(\"Arial\", size=12)\n",
        "    pdf.multi_cell(0, 10, text)\n",
        "    pdf.output(f\"data/papers/{filename}\")\n",
        "\n",
        "# Generate 15 dummy PDFs matching your labels.csv\n",
        "for i in range(1, 16):\n",
        "    filename = f\"paper{i:02d}.pdf\"\n",
        "    text = f\"This is the content of {filename}. It simulates a research paper for testing purposes.\"\n",
        "    create_dummy_pdf(filename, text)\n"
      ],
      "metadata": {
        "id": "-k1dspniumko"
      },
      "id": "-k1dspniumko",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.listdir(\"data/papers\"))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_l7Af7juwRw",
        "outputId": "affbd9b9-9987-4b7c-836d-f75c225e0de4"
      },
      "id": "r_l7Af7juwRw",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['paper15.pdf', 'paper06.pdf', 'paper07.pdf', 'paper03.pdf', 'paper02.pdf', 'paper08.pdf', 'paper01.pdf', 'paper10.pdf', 'paper14.pdf', 'paper13.pdf', 'paper09.pdf', 'paper04.pdf', 'paper11.pdf', 'paper12.pdf', 'paper05.pdf']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "QWWosCHRtW9Q",
        "outputId": "95d4cfff-2f95-46f6-a33c-91e715dc7d7e"
      },
      "id": "QWWosCHRtW9Q",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-aebbe48b-2f02-404e-a755-3e31088a7a77\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-aebbe48b-2f02-404e-a755-3e31088a7a77\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving labels.csv to labels.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p data\n",
        "!mv labels.csv data/\n"
      ],
      "metadata": {
        "id": "wQ3cGGmhtmk1"
      },
      "id": "wQ3cGGmhtmk1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "80074a2c",
      "metadata": {
        "id": "80074a2c"
      },
      "source": [
        "## 🏷️ Step 3: Classify a Paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4ae84d5",
      "metadata": {
        "id": "e4ae84d5"
      },
      "outputs": [],
      "source": [
        "import joblib\n",
        "\n",
        "model = joblib.load(\"models/classifier.pkl\")\n",
        "\n",
        "def classify_paper(text):\n",
        "    embedding = embedder.encode([text])\n",
        "    label = model.predict(embedding)[0]\n",
        "    return \"Publishable\" if label == 1 else \"Non-Publishable\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9ddd2aa",
      "metadata": {
        "id": "b9ddd2aa"
      },
      "source": [
        "## 🧾 Step 4: Generate Justification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "849e4425",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84,
          "referenced_widgets": [
            "e1a9d9da3750457ab772780661db0de2",
            "598783bca4be4280820d7f7e91d5c0ad",
            "fe407353c1fd4f2d9e011eb62ace49ef",
            "b40894b9da44499f83de99388516c7c6",
            "441df1946ac24933a2cf09745a192b78",
            "80c7f19e4c0c4c23b32ab97a8fa34759",
            "dd912d36cf3748fbbb87649e40281be7",
            "06b03ac76e8a4e28b5ffa5433f478d6a",
            "9cb68d1536ce4d6bb0686fabae567a92",
            "2902635410984d57ab77db517e0468ce",
            "9425ca8831bd4ab78bacb0f4a3313928"
          ]
        },
        "id": "849e4425",
        "outputId": "1698642a-3f91-4901-b468-3613475371df"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e1a9d9da3750457ab772780661db0de2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:accelerate.big_modeling:Some parameters are on the meta device because they were offloaded to the cpu and disk.\n",
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "generator = pipeline(\"text-generation\", model=\"tiiuae/falcon-7b-instruct\", device_map=\"auto\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_justification(text, label):\n",
        "    # your logic here\n",
        "    return f\"This paper was classified as {label} because ...\"\n"
      ],
      "metadata": {
        "id": "vZhOSwfAzSUc"
      },
      "id": "vZhOSwfAzSUc",
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.makedirs(\"results\", exist_ok=True)\n"
      ],
      "metadata": {
        "id": "g2xrAf2azbwg"
      },
      "id": "g2xrAf2azbwg",
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.makedirs(\"results\", exist_ok=True)\n",
        "\n",
        "df_results = pd.DataFrame(results, columns=[\"Filename\", \"Publishability\", \"Justification\"])\n",
        "df_results.to_csv(\"results/results.csv\", index=False)\n",
        "df_results.head()\n"
      ],
      "metadata": {
        "id": "NFyq1ddjzc7Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "e624d28a-89dc-4dc2-bbc6-ad248f85de51"
      },
      "id": "NFyq1ddjzc7Y",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [Filename, Publishability, Justification]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1549bde3-ae34-49c7-8ec8-bd65d86a622b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Publishability</th>\n",
              "      <th>Justification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1549bde3-ae34-49c7-8ec8-bd65d86a622b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-1549bde3-ae34-49c7-8ec8-bd65d86a622b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-1549bde3-ae34-49c7-8ec8-bd65d86a622b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "repr_error": "Out of range float values are not JSON compliant: nan"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "source": [
        "from google.colab import sheets\n",
        "sheet = sheets.InteractiveSheet(df=df_results)"
      ],
      "cell_type": "code",
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "https://docs.google.com/spreadsheets/d/1iB0o0g3OzEx0bwOoXCbLKYfdd_z4J9mTJhCGcvhhWa8/edit#gid=0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.lib.display.IFrame at 0x7c57c0c2dd90>"
            ],
            "text/html": [
              "\n",
              "        <iframe\n",
              "            width=\"100%\"\n",
              "            height=\"600\"\n",
              "            src=\"https://docs.google.com/spreadsheets/d/1iB0o0g3OzEx0bwOoXCbLKYfdd_z4J9mTJhCGcvhhWa8/edit?rm=embedded#gid=0\"\n",
              "            frameborder=\"0\"\n",
              "            allowfullscreen\n",
              "            \n",
              "        ></iframe>\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 639
        },
        "id": "BAnoMNGD0KOL",
        "outputId": "593dd837-ff5e-4a55-941d-a095c6134fb2"
      },
      "id": "BAnoMNGD0KOL"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LXLzyn020A_X"
      },
      "id": "LXLzyn020A_X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "54f9d0e6",
      "metadata": {
        "id": "54f9d0e6"
      },
      "source": [
        "## 🔄 Step 5: Full Pipeline Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "f381023b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "f381023b",
        "outputId": "328e517b-9ace-4f85-a5fc-e12dc718d5fb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Filename   Publishability  \\\n",
              "0  paper15.pdf  Non-Publishable   \n",
              "1  paper06.pdf      Publishable   \n",
              "2  paper07.pdf  Non-Publishable   \n",
              "3  paper03.pdf  Non-Publishable   \n",
              "4  paper02.pdf      Publishable   \n",
              "\n",
              "                                       Justification  \n",
              "0  This paper was classified as Non-Publishable b...  \n",
              "1  This paper was classified as Publishable becau...  \n",
              "2  This paper was classified as Non-Publishable b...  \n",
              "3  This paper was classified as Non-Publishable b...  \n",
              "4  This paper was classified as Publishable becau...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8f57ff90-858e-46a8-9460-8a1a2022195c\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Filename</th>\n",
              "      <th>Publishability</th>\n",
              "      <th>Justification</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>paper15.pdf</td>\n",
              "      <td>Non-Publishable</td>\n",
              "      <td>This paper was classified as Non-Publishable b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>paper06.pdf</td>\n",
              "      <td>Publishable</td>\n",
              "      <td>This paper was classified as Publishable becau...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>paper07.pdf</td>\n",
              "      <td>Non-Publishable</td>\n",
              "      <td>This paper was classified as Non-Publishable b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>paper03.pdf</td>\n",
              "      <td>Non-Publishable</td>\n",
              "      <td>This paper was classified as Non-Publishable b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>paper02.pdf</td>\n",
              "      <td>Publishable</td>\n",
              "      <td>This paper was classified as Publishable becau...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8f57ff90-858e-46a8-9460-8a1a2022195c')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-8f57ff90-858e-46a8-9460-8a1a2022195c button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-8f57ff90-858e-46a8-9460-8a1a2022195c');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-9ad7e719-7f29-442a-bbfa-63fe2086035d\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9ad7e719-7f29-442a-bbfa-63fe2086035d')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-9ad7e719-7f29-442a-bbfa-63fe2086035d button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_results",
              "summary": "{\n  \"name\": \"df_results\",\n  \"rows\": 15,\n  \"fields\": [\n    {\n      \"column\": \"Filename\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"paper13.pdf\",\n          \"paper04.pdf\",\n          \"paper15.pdf\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Publishability\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Publishable\",\n          \"Non-Publishable\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Justification\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"This paper was classified as Publishable because ...\",\n          \"This paper was classified as Non-Publishable because ...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "results = []\n",
        "paper_dir = \"data/papers\"\n",
        "\n",
        "for filename in os.listdir(paper_dir):\n",
        "    path = os.path.join(paper_dir, filename)\n",
        "    text = extract_text_from_pdf(path)\n",
        "    label = classify_paper(text)\n",
        "    reason = generate_justification(text, label)\n",
        "    results.append([filename, label, reason])\n",
        "\n",
        "df_results = pd.DataFrame(results, columns=[\"Filename\", \"Publishability\", \"Justification\"])\n",
        "df_results.to_csv(\"results/results.csv\", index=False)\n",
        "df_results.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f381ed8c",
      "metadata": {
        "id": "f381ed8c"
      },
      "source": [
        "## ❓ Step 6: Interactive Q&A System"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4IAI6Wyzubz",
        "outputId": "dbbed46a-0124-49fd-f0f6-9478492a5b9f"
      },
      "id": "U4IAI6Wyzubz",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.11/dist-packages (0.3.21)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.51 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.51)\n",
            "Requirement already satisfied: langchain<1.0.0,>=0.3.23 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.23)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.8.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.3.28)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.4.0)\n",
            "Requirement already satisfied: numpy<3,>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.19.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (0.3.8)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain<1.0.0,>=0.3.23->langchain-community) (2.11.3)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.51->langchain-community) (4.13.1)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (3.10.16)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-community) (0.23.0)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.51->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.23->langchain-community) (0.4.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "4f3882b1",
      "metadata": {
        "id": "4f3882b1"
      },
      "outputs": [],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "def load_chunks(text):\n",
        "    splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
        "    return splitter.create_documents([text])\n",
        "\n",
        "def build_qa_chain(documents):\n",
        "    embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "    vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "\n",
        "    pipe = pipeline(\"text-generation\", model=\"mistralai/Mistral-7B-Instruct-v0.1\", device_map=\"auto\")\n",
        "    llm = HuggingFacePipeline(pipeline=pipe)\n",
        "\n",
        "    retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
        "    qa = RetrievalQA.from_chain_type(llm=llm, retriever=retriever, chain_type=\"stuff\")\n",
        "    return qa\n",
        "\n",
        "def interactive_qa(pdf_path):\n",
        "    text = extract_text_from_pdf(pdf_path)\n",
        "    chunks = load_chunks(text)\n",
        "    qa = build_qa_chain(chunks)\n",
        "\n",
        "    print(f\"\\nInteractive Q&A for {pdf_path}\")\n",
        "    print(\"Type 'exit' to quit.\")\n",
        "    while True:\n",
        "        query = input(\"\\nAsk your question: \")\n",
        "        if query.lower() == \"exit\":\n",
        "            break\n",
        "        result = qa.run(query)\n",
        "        print(f\"\\nAnswer: {result}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # This will prompt you to upload the ZIP file from your computer\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "bbqY9rgb9cHd",
        "outputId": "9a9c8463-47b2-44d6-cdd2-794b0e9256d6"
      },
      "id": "bbqY9rgb9cHd",
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1dfeb1a8-5e59-48b0-985c-110b6f179b62\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1dfeb1a8-5e59-48b0-985c-110b6f179b62\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving EARC Dataset-20250417T115257Z-0012.zip to EARC Dataset-20250417T115257Z-0012.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.listdir('.'))  # Should show your ZIP file in the output\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0XC7LNt-bIC",
        "outputId": "b3315bf1-3bdc-4211-cdda-ed9d64220ebd"
      },
      "id": "o0XC7LNt-bIC",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['.config', 'EARC Dataset-20250417T115257Z-001.zip', 'models', 'EARC Dataset-20250417T115257Z-0012.zip', 'data', 'results', 'sample_data']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = 'EARC Dataset-20250417T115257Z-0012.zip'  # Replace with your actual file name\n",
        "extract_path = './extracted_papers'\n",
        "\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Extraction complete. Files are in:\", extract_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bMctqYzm-144",
        "outputId": "dc962b28-aa03-4f3c-8304-3591a13ff7f8"
      },
      "id": "bMctqYzm-144",
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extraction complete. Files are in: ./extracted_papers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.listdir(extract_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixpSpi6C-6yR",
        "outputId": "43547c57-83b7-42dc-c2ef-4a3b8772d8d9"
      },
      "id": "ixpSpi6C-6yR",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['EARC Dataset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sVcsoSf_Fje",
        "outputId": "b9c4dd66-5cf8-44b8-f0ba-b6204e54a73d"
      },
      "id": "5sVcsoSf_Fje",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Check extracted files\n",
        "extract_path = './extracted_papers'\n",
        "print(\"Contents of extraction folder:\", os.listdir(extract_path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cBv7pzf_H0q",
        "outputId": "29f85c2f-e2d5-4084-f71c-d68c381c7c41"
      },
      "id": "5cBv7pzf_H0q",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Contents of extraction folder: ['EARC Dataset']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find first PDF in nested directories\n",
        "def find_first_pdf(root_dir):\n",
        "    for root, dirs, files in os.walk(root_dir):\n",
        "        for file in files:\n",
        "            if file.lower().endswith('.pdf'):\n",
        "                return os.path.join(root, file)\n",
        "    return None\n",
        "\n",
        "sample_pdf = find_first_pdf(extract_path)\n",
        "\n",
        "if not sample_pdf:\n",
        "    raise FileNotFoundError(\"No PDF found in extracted files\")\n"
      ],
      "metadata": {
        "id": "0kVdU88n_kpI"
      },
      "id": "0kVdU88n_kpI",
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use absolute paths for clarity\n",
        "sample_pdf = os.path.abspath(sample_pdf)\n",
        "print(\"Attempting to open:\", sample_pdf)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpFUN8t5_oCw",
        "outputId": "f8b36ba1-a775-4656-a394-c3ef97ebc7e4"
      },
      "id": "OpFUN8t5_oCw",
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Attempting to open: /content/extracted_papers/EARC Dataset/Papers/P017.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fitz\n",
        "\n",
        "try:\n",
        "    with fitz.open(sample_pdf) as doc:\n",
        "        print(f\"Successfully opened {os.path.basename(sample_pdf)}\")\n",
        "        print(\"Number of pages:\", len(doc))\n",
        "except Exception as e:\n",
        "    print(f\"Failed to open PDF: {str(e)}\")\n",
        "    print(\"Common fixes:\")\n",
        "    print(\"- Re-upload ZIP file\")\n",
        "    print(\"- Check file integrity\")\n",
        "    print(\"- Use `!apt install libxml2-dev libxslt-dev` for dependencies\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nevGsvSY_rrL",
        "outputId": "f4cb2c09-7561-4777-ac31-3b5b483dacb7"
      },
      "id": "nevGsvSY_rrL",
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully opened P017.pdf\n",
            "Number of pages: 9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "# Revised extraction and processing\n",
        "extract_path = './extracted_papers'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract with directory awareness\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Process all PDFs\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.pdf'):\n",
        "            pdf_path = os.path.join(root, file)\n",
        "            try:\n",
        "                with fitz.open(pdf_path) as doc:  # This line needs indented block\n",
        "                    # Minimal required processing (e.g., page count)\n",
        "                    print(f\"Processing {file} ({len(doc)} pages)\")\n",
        "                    # Add your actual PDF parsing logic here\n",
        "\n",
        "            except fitz.FileDataError:\n",
        "                print(f\"Skipping corrupted/non-PDF file: {pdf_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qfnwpM1F_wB3",
        "outputId": "338e2425-e0e4-4973-fedb-677bfb00d03b"
      },
      "id": "qfnwpM1F_wB3",
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing P017.pdf (9 pages)\n",
            "Processing P078.pdf (5 pages)\n",
            "Processing P059.pdf (8 pages)\n",
            "Processing P070.pdf (11 pages)\n",
            "Processing P106.pdf (5 pages)\n",
            "Processing P073.pdf (14 pages)\n",
            "Processing P131.pdf (3 pages)\n",
            "Processing P067.pdf (4 pages)\n",
            "Processing P126.pdf (8 pages)\n",
            "Processing P040.pdf (3 pages)\n",
            "Processing P113.pdf (4 pages)\n",
            "Processing P096.pdf (14 pages)\n",
            "Processing P097.pdf (14 pages)\n",
            "Processing P048.pdf (14 pages)\n",
            "Processing P074.pdf (3 pages)\n",
            "Processing P087.pdf (6 pages)\n",
            "Processing P015.pdf (4 pages)\n",
            "Processing P031.pdf (5 pages)\n",
            "Processing P076.pdf (11 pages)\n",
            "Processing P082.pdf (3 pages)\n",
            "Processing P125.pdf (9 pages)\n",
            "Processing P008.pdf (5 pages)\n",
            "Processing P051.pdf (5 pages)\n",
            "Processing P075.pdf (5 pages)\n",
            "Processing P115.pdf (5 pages)\n",
            "Processing P081.pdf (8 pages)\n",
            "Processing P112.pdf (5 pages)\n",
            "Processing P089.pdf (4 pages)\n",
            "Processing P094.pdf (14 pages)\n",
            "Processing P056.pdf (13 pages)\n",
            "Processing P062.pdf (7 pages)\n",
            "Processing P032.pdf (14 pages)\n",
            "Processing P117.pdf (9 pages)\n",
            "Processing P103.pdf (4 pages)\n",
            "Processing P086.pdf (13 pages)\n",
            "Processing P093.pdf (6 pages)\n",
            "Processing P116.pdf (8 pages)\n",
            "Processing P100.pdf (15 pages)\n",
            "Processing P118.pdf (5 pages)\n",
            "Processing P023.pdf (6 pages)\n",
            "Processing P005.pdf (4 pages)\n",
            "Processing P091.pdf (5 pages)\n",
            "Processing P123.pdf (9 pages)\n",
            "Processing P130.pdf (6 pages)\n",
            "Processing P033.pdf (6 pages)\n",
            "Processing P055.pdf (3 pages)\n",
            "Processing P069.pdf (13 pages)\n",
            "Processing P039.pdf (13 pages)\n",
            "Processing P013.pdf (2 pages)\n",
            "Processing P011.pdf (5 pages)\n",
            "Processing P026.pdf (6 pages)\n",
            "Processing P035.pdf (6 pages)\n",
            "Processing P021.pdf (3 pages)\n",
            "Processing P041.pdf (8 pages)\n",
            "Processing P095.pdf (6 pages)\n",
            "Processing P019.pdf (7 pages)\n",
            "Processing P030.pdf (4 pages)\n",
            "Processing P072.pdf (2 pages)\n",
            "Processing P028.pdf (7 pages)\n",
            "Processing P133.pdf (6 pages)\n",
            "Processing P002.pdf (15 pages)\n",
            "Processing P063.pdf (3 pages)\n",
            "Processing P127.pdf (3 pages)\n",
            "Processing P025.pdf (8 pages)\n",
            "Processing P104.pdf (11 pages)\n",
            "Processing P046.pdf (6 pages)\n",
            "Processing P071.pdf (4 pages)\n",
            "Processing P088.pdf (11 pages)\n",
            "Processing P090.pdf (6 pages)\n",
            "Processing P045.pdf (8 pages)\n",
            "Processing P084.pdf (6 pages)\n",
            "Processing P042.pdf (3 pages)\n",
            "Processing P029.pdf (6 pages)\n",
            "Processing P092.pdf (6 pages)\n",
            "Processing P036.pdf (14 pages)\n",
            "Processing P010.pdf (6 pages)\n",
            "Processing P099.pdf (5 pages)\n",
            "Processing P050.pdf (5 pages)\n",
            "Processing P004.pdf (7 pages)\n",
            "Processing P009.pdf (5 pages)\n",
            "Processing P061.pdf (10 pages)\n",
            "Processing P068.pdf (6 pages)\n",
            "Processing P001.pdf (3 pages)\n",
            "Processing P134.pdf (12 pages)\n",
            "Processing P085.pdf (7 pages)\n",
            "Processing P007.pdf (5 pages)\n",
            "Processing P119.pdf (14 pages)\n",
            "Processing P027.pdf (5 pages)\n",
            "Processing P105.pdf (14 pages)\n",
            "Processing P014.pdf (3 pages)\n",
            "Processing P044.pdf (5 pages)\n",
            "Processing P102.pdf (8 pages)\n",
            "Processing P038.pdf (10 pages)\n",
            "Processing P065.pdf (3 pages)\n",
            "Processing P110.pdf (3 pages)\n",
            "Processing P079.pdf (2 pages)\n",
            "Processing P049.pdf (5 pages)\n",
            "Processing P022.pdf (6 pages)\n",
            "Processing P060.pdf (8 pages)\n",
            "Processing P122.pdf (6 pages)\n",
            "Processing P109.pdf (4 pages)\n",
            "Processing P020.pdf (6 pages)\n",
            "Processing P024.pdf (9 pages)\n",
            "Processing P120.pdf (5 pages)\n",
            "Processing P064.pdf (7 pages)\n",
            "Processing P054.pdf (10 pages)\n",
            "Processing P132.pdf (5 pages)\n",
            "Processing P018.pdf (6 pages)\n",
            "Processing P003.pdf (5 pages)\n",
            "Processing P080.pdf (9 pages)\n",
            "Processing P124.pdf (7 pages)\n",
            "Processing P107.pdf (12 pages)\n",
            "Processing P058.pdf (7 pages)\n",
            "Processing P057.pdf (2 pages)\n",
            "Processing P012.pdf (12 pages)\n",
            "Processing P037.pdf (4 pages)\n",
            "Processing P052.pdf (5 pages)\n",
            "Processing P083.pdf (5 pages)\n",
            "Processing P034.pdf (6 pages)\n",
            "Processing P066.pdf (6 pages)\n",
            "Processing P114.pdf (4 pages)\n",
            "Processing P101.pdf (3 pages)\n",
            "Processing P121.pdf (6 pages)\n",
            "Processing P047.pdf (15 pages)\n",
            "Processing P111.pdf (15 pages)\n",
            "Processing P135.pdf (7 pages)\n",
            "Processing P128.pdf (10 pages)\n",
            "Processing P098.pdf (5 pages)\n",
            "Processing P129.pdf (14 pages)\n",
            "Processing P108.pdf (2 pages)\n",
            "Processing P077.pdf (11 pages)\n",
            "Processing P016.pdf (10 pages)\n",
            "Processing P006.pdf (7 pages)\n",
            "Processing P043.pdf (14 pages)\n",
            "Processing P053.pdf (14 pages)\n",
            "Processing R015.pdf (6 pages)\n",
            "Processing R009.pdf (7 pages)\n",
            "Processing R012.pdf (6 pages)\n",
            "Processing R014.pdf (7 pages)\n",
            "Processing R013.pdf (7 pages)\n",
            "Processing R011.pdf (8 pages)\n",
            "Processing R007.pdf (10 pages)\n",
            "Processing R006.pdf (7 pages)\n",
            "Processing R008.pdf (9 pages)\n",
            "Processing R010.pdf (10 pages)\n",
            "Processing R003.pdf (14 pages)\n",
            "Processing R002.pdf (14 pages)\n",
            "Processing R001.pdf (12 pages)\n",
            "Processing R005.pdf (11 pages)\n",
            "Processing R004.pdf (5 pages)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verify PDF readability\n",
        "def is_valid_pdf(path):\n",
        "    try:\n",
        "        with fitz.open(path) as doc:\n",
        "            return len(doc) > 0\n",
        "    except:\n",
        "        return False\n",
        "\n",
        "print(\"Valid PDF check:\", is_valid_pdf(sample_pdf))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOp5IPQcAgQq",
        "outputId": "2eb29150-66c3-4dc9-b668-310322b0d060"
      },
      "id": "SOp5IPQcAgQq",
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valid PDF check: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nm-rMf_kBEMb",
        "outputId": "25bbdf69-da40-44c5-dbc8-f5bdb9bfb936"
      },
      "id": "nm-rMf_kBEMb",
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m153.6/232.6 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')  # Ensure proper mounting\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lK3dx3R3DS73",
        "outputId": "b743ec51-1ea2-4930-f2c3-31649b779ca6"
      },
      "id": "lK3dx3R3DS73",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Correct path format for Colab\n",
        "zip_path = '/content/drive/MyDrive/EARC Dataset-20250417T115257Z-0012.zip'\n",
        "\n",
        "# Verify file existence\n",
        "if not os.path.exists(zip_path):\n",
        "    print(\"Error: File not found. Check:\")\n",
        "    print(f\"1. Filename matches exactly: {os.path.basename(zip_path)}\")\n",
        "    print(f\"2. File exists in Google Drive's root folder\")\n",
        "else:\n",
        "    print(\"File verified successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leko4ZWKDVaE",
        "outputId": "5c299837-b84f-43df-9366-8254f9435d44"
      },
      "id": "leko4ZWKDVaE",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File not found. Check:\n",
            "1. Filename matches exactly: EARC Dataset-20250417T115257Z-0012.zip\n",
            "2. File exists in Google Drive's root folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "extract_path = '/content/extracted_papers'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        # Extract only PDFs from Papers folder\n",
        "        for file in zip_ref.namelist():\n",
        "            if 'Papers/' in file and file.endswith('.pdf'):\n",
        "                zip_ref.extract(file, extract_path)\n",
        "\n",
        "    print(f\"Extracted to: {extract_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Critical error: Re-upload ZIP file to Google Drive\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i6O88_kkDbQR",
        "outputId": "7f099c1d-5ce0-4f6d-f8dc-d9abe6f007e4"
      },
      "id": "i6O88_kkDbQR",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Critical error: Re-upload ZIP file to Google Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find actual extracted path\n",
        "final_path = os.path.join(extract_path, 'Papers') if os.path.exists(os.path.join(extract_path, 'Papers')) else extract_path\n",
        "\n",
        "print(\"Extracted PDFs:\", len([f for f in os.listdir(final_path) if f.endswith('.pdf')]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7ivhyqMDfm6",
        "outputId": "487cff48-d483-4453-c4ed-903ffccd8614"
      },
      "id": "n7ivhyqMDfm6",
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted PDFs: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Full processing pipeline\n",
        "for root, dirs, files in os.walk(extract_path):\n",
        "    for file in files:\n",
        "        if file.endswith('.pdf'):\n",
        "            pdf_path = os.path.join(root, file)\n",
        "            try:\n",
        "                # Add your PDF processing logic here\n",
        "                print(f\"Processing {file}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Skipped {file}: {str(e)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2Ib_alnDibk",
        "outputId": "b21bdc91-f06b-43e1-8de0-258fa1b65119"
      },
      "id": "H2Ib_alnDibk",
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing P017.pdf\n",
            "Processing P078.pdf\n",
            "Processing P059.pdf\n",
            "Processing P070.pdf\n",
            "Processing P106.pdf\n",
            "Processing P073.pdf\n",
            "Processing P131.pdf\n",
            "Processing P067.pdf\n",
            "Processing P126.pdf\n",
            "Processing P040.pdf\n",
            "Processing P113.pdf\n",
            "Processing P096.pdf\n",
            "Processing P097.pdf\n",
            "Processing P048.pdf\n",
            "Processing P074.pdf\n",
            "Processing P087.pdf\n",
            "Processing P015.pdf\n",
            "Processing P031.pdf\n",
            "Processing P076.pdf\n",
            "Processing P082.pdf\n",
            "Processing P125.pdf\n",
            "Processing P008.pdf\n",
            "Processing P051.pdf\n",
            "Processing P075.pdf\n",
            "Processing P115.pdf\n",
            "Processing P081.pdf\n",
            "Processing P112.pdf\n",
            "Processing P089.pdf\n",
            "Processing P094.pdf\n",
            "Processing P056.pdf\n",
            "Processing P062.pdf\n",
            "Processing P032.pdf\n",
            "Processing P117.pdf\n",
            "Processing P103.pdf\n",
            "Processing P086.pdf\n",
            "Processing P093.pdf\n",
            "Processing P116.pdf\n",
            "Processing P100.pdf\n",
            "Processing P118.pdf\n",
            "Processing P023.pdf\n",
            "Processing P005.pdf\n",
            "Processing P091.pdf\n",
            "Processing P123.pdf\n",
            "Processing P130.pdf\n",
            "Processing P033.pdf\n",
            "Processing P055.pdf\n",
            "Processing P069.pdf\n",
            "Processing P039.pdf\n",
            "Processing P013.pdf\n",
            "Processing P011.pdf\n",
            "Processing P026.pdf\n",
            "Processing P035.pdf\n",
            "Processing P021.pdf\n",
            "Processing P041.pdf\n",
            "Processing P095.pdf\n",
            "Processing P019.pdf\n",
            "Processing P030.pdf\n",
            "Processing P072.pdf\n",
            "Processing P028.pdf\n",
            "Processing P133.pdf\n",
            "Processing P002.pdf\n",
            "Processing P063.pdf\n",
            "Processing P127.pdf\n",
            "Processing P025.pdf\n",
            "Processing P104.pdf\n",
            "Processing P046.pdf\n",
            "Processing P071.pdf\n",
            "Processing P088.pdf\n",
            "Processing P090.pdf\n",
            "Processing P045.pdf\n",
            "Processing P084.pdf\n",
            "Processing P042.pdf\n",
            "Processing P029.pdf\n",
            "Processing P092.pdf\n",
            "Processing P036.pdf\n",
            "Processing P010.pdf\n",
            "Processing P099.pdf\n",
            "Processing P050.pdf\n",
            "Processing P004.pdf\n",
            "Processing P009.pdf\n",
            "Processing P061.pdf\n",
            "Processing P068.pdf\n",
            "Processing P001.pdf\n",
            "Processing P134.pdf\n",
            "Processing P085.pdf\n",
            "Processing P007.pdf\n",
            "Processing P119.pdf\n",
            "Processing P027.pdf\n",
            "Processing P105.pdf\n",
            "Processing P014.pdf\n",
            "Processing P044.pdf\n",
            "Processing P102.pdf\n",
            "Processing P038.pdf\n",
            "Processing P065.pdf\n",
            "Processing P110.pdf\n",
            "Processing P079.pdf\n",
            "Processing P049.pdf\n",
            "Processing P022.pdf\n",
            "Processing P060.pdf\n",
            "Processing P122.pdf\n",
            "Processing P109.pdf\n",
            "Processing P020.pdf\n",
            "Processing P024.pdf\n",
            "Processing P120.pdf\n",
            "Processing P064.pdf\n",
            "Processing P054.pdf\n",
            "Processing P132.pdf\n",
            "Processing P018.pdf\n",
            "Processing P003.pdf\n",
            "Processing P080.pdf\n",
            "Processing P124.pdf\n",
            "Processing P107.pdf\n",
            "Processing P058.pdf\n",
            "Processing P057.pdf\n",
            "Processing P012.pdf\n",
            "Processing P037.pdf\n",
            "Processing P052.pdf\n",
            "Processing P083.pdf\n",
            "Processing P034.pdf\n",
            "Processing P066.pdf\n",
            "Processing P114.pdf\n",
            "Processing P101.pdf\n",
            "Processing P121.pdf\n",
            "Processing P047.pdf\n",
            "Processing P111.pdf\n",
            "Processing P135.pdf\n",
            "Processing P128.pdf\n",
            "Processing P098.pdf\n",
            "Processing P129.pdf\n",
            "Processing P108.pdf\n",
            "Processing P077.pdf\n",
            "Processing P016.pdf\n",
            "Processing P006.pdf\n",
            "Processing P043.pdf\n",
            "Processing P053.pdf\n",
            "Processing R015.pdf\n",
            "Processing R009.pdf\n",
            "Processing R012.pdf\n",
            "Processing R014.pdf\n",
            "Processing R013.pdf\n",
            "Processing R011.pdf\n",
            "Processing R007.pdf\n",
            "Processing R006.pdf\n",
            "Processing R008.pdf\n",
            "Processing R010.pdf\n",
            "Processing R003.pdf\n",
            "Processing R002.pdf\n",
            "Processing R001.pdf\n",
            "Processing R005.pdf\n",
            "Processing R004.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)  # Force remount if needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqhSSujUEj1h",
        "outputId": "6a49913e-fc5a-412a-d69b-088d901b523f"
      },
      "id": "cqhSSujUEj1h",
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Correct path format (note \"My Drive\" vs \"MyDrive\")\n",
        "zip_path = '/content/drive/My Drive/EARC Dataset-20250417T115257Z-0012.zip'\n",
        "\n",
        "# Verify existence\n",
        "if not os.path.exists(zip_path):\n",
        "    print(f\"Error: File not found. Check:\")\n",
        "    print(f\"1. Filename matches exactly (including spaces/numbers)\")\n",
        "    print(f\"2. File is in Google Drive's root folder\")\n",
        "else:\n",
        "    print(\"File verified successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qroAR8oqEpxM",
        "outputId": "07a43c6a-3b22-4bc3-e4d5-3701a413e829"
      },
      "id": "qroAR8oqEpxM",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File not found. Check:\n",
            "1. Filename matches exactly (including spaces/numbers)\n",
            "2. File is in Google Drive's root folder\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use quotes for paths with spaces\n",
        "zip_path = '/content/drive/My Drive/EARC Dataset-20250417T115257Z-0012.zip'\n",
        "extract_path = '/content/extracted_papers'\n",
        "\n",
        "# Verify path exists\n",
        "if not os.path.exists(zip_path):\n",
        "    print(f\"Error: File not found. Check path: {zip_path}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46Ysx_P2ErYi",
        "outputId": "fb1a85bb-b447-4c1f-bfea-e616ccfd1aa4"
      },
      "id": "46Ysx_P2ErYi",
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: File not found. Check path: /content/drive/My Drive/EARC Dataset-20250417T115257Z-0012.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "\n",
        "# Get shareable link from Google Drive (replace FILE_ID)\n",
        "FILE_ID = \"1YOUR_FILE_ID_HERE\"  # From Drive's shareable link\n",
        "!gdown \"https://drive.google.com/uc?id={FILE_ID}\"\n",
        "\n",
        "# Now use local path\n",
        "zip_path = \"/content/EARC Dataset-20250417T115257Z-0012.zip\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEs1KzPDFKNq",
        "outputId": "ba0778f3-48cd-485b-f480-0b73c9c2787e"
      },
      "id": "SEs1KzPDFKNq",
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1YOUR_FILE_ID_HERE\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clean install latest version\n",
        "!pip install --upgrade --no-cache-dir gdown\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9xWa9wxCFjEL",
        "outputId": "6638a47e-a279-4b37-e06a-95f44d1190dd"
      },
      "id": "9xWa9wxCFjEL",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2025.1.31)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.cache/gdown/\n",
        "!cp /content/cookies.txt ~/.cache/gdown/\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSBGULwzFlrF",
        "outputId": "73206b0d-d0f8-4d77-a4a0-b59acf8057c2"
      },
      "id": "LSBGULwzFlrF",
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '/content/cookies.txt': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace YOUR_FILE_ID with actual ID from shareable link\n",
        "FILE_ID = \"1YOUR_FILE_ID_HERE\"\n",
        "!gdown \"https://drive.google.com/uc?id={FILE_ID}\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FtyYlRD0Fqq6",
        "outputId": "dc1c9a1e-1444-4b10-fdd1-78d5a26b8df8"
      },
      "id": "FtyYlRD0Fqq6",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to retrieve file url:\n",
            "\n",
            "\tCannot retrieve the public link of the file. You may need to change\n",
            "\tthe permission to 'Anyone with the link', or have had many accesses.\n",
            "\tCheck FAQ in https://github.com/wkentaro/gdown?tab=readme-ov-file#faq.\n",
            "\n",
            "You may still be able to access the file from the browser:\n",
            "\n",
            "\thttps://drive.google.com/uc?id=1YOUR_FILE_ID_HERE\n",
            "\n",
            "but Gdown can't. Please check connections and permissions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if os.path.exists(\"EARC Dataset-20250417T115257Z-0012.zip\"):\n",
        "    print(\"Download successful!\")\n",
        "else:\n",
        "    print(\"Retry with cookies/wget method\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoNtcpdKFsjl",
        "outputId": "f9cd3f88-1c42-405c-c17f-d806010d57c5"
      },
      "id": "WoNtcpdKFsjl",
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Download successful!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Mount Google Drive and install dependencies\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "!pip install pymupdf scipdf_parser transformers\n",
        "\n",
        "# Step 2: Extract Papers folder from ZIP\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/EARC Dataset-20250417T115257Z-0012.zip'  # Update path\n",
        "extract_path = '/content/extracted_papers'\n",
        "\n",
        "# Create extraction directory\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "\n",
        "# Extract only Papers folder\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    for file in zip_ref.namelist():\n",
        "        if file.startswith('Papers/') and file.endswith('.pdf'):\n",
        "            zip_ref.extract(file, extract_path)\n",
        "\n",
        "# Verify extraction\n",
        "papers_dir = os.path.join(extract_path, 'Papers')\n",
        "print(f\"Extracted {len(os.listdir(papers_dir))} PDFs\")\n",
        "\n",
        "# Step 3: PDF Processing and Feature Extraction\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "def process_paper(pdf_path):\n",
        "    \"\"\"Extract structured content from PDF\"\"\"\n",
        "    doc = fitz.open(pdf_path)\n",
        "    paper_data = {\n",
        "        'text': '',\n",
        "        'sections': {},\n",
        "        'abstract': '',\n",
        "        'references': []\n",
        "    }\n",
        "\n",
        "    # Extract text and sections\n",
        "    for page in doc:\n",
        "        paper_data['text'] += page.get_text()\n",
        "\n",
        "    # Simple section detection (customize as needed)\n",
        "    sections = ['abstract', 'introduction', 'methodology', 'results', 'conclusion']\n",
        "    for sec in sections:\n",
        "        if sec in paper_data['text'].lower():\n",
        "            start = paper_data['text'].lower().find(sec)\n",
        "            paper_data['sections'][sec] = paper_data['text'][start:start+1000]\n",
        "\n",
        "    return paper_data\n",
        "\n",
        "# Step 4: Publishability Classifier\n",
        "from transformers import pipeline\n",
        "\n",
        "classifier = pipeline(\"text-classification\",\n",
        "                    model=\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "def classify_paper(paper_data):\n",
        "    \"\"\"Classify paper using LLM\"\"\"\n",
        "    prompt = f\"\"\"\n",
        "    Analyze this research paper for publishability:\n",
        "    Abstract: {paper_data.get('abstract', '')[:500]}\n",
        "    Sections: {list(paper_data['sections'].keys())}\n",
        "\n",
        "    Consider:\n",
        "    - Methodological soundness\n",
        "    - Result validity\n",
        "    - Academic rigor\n",
        "    - Logical coherence\n",
        "\n",
        "    Decision (Publishable=1/Non-Publishable=0):\"\"\"\n",
        "\n",
        "    result = classifier(prompt, max_length=10)\n",
        "    return 1 if \"1\" in result[0]['generated_text'] else 0\n",
        "\n",
        "# Step 5: Generate Rationale\n",
        "def generate_rationale(paper_data, prediction):\n",
        "    \"\"\"Generate justification using LLM\"\"\"\n",
        "    justifier = pipeline(\"text-generation\",\n",
        "                       model=\"mistralai/Mistral-7B-Instruct-v0.2\")\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Provide a 100-word rationale for {'publish' if prediction else 'reject'} decision:\n",
        "    Paper Sections: {list(paper_data['sections'].keys())}\n",
        "    Key Content: {paper_data['text'][:1000]}\n",
        "\n",
        "    Focus on:\n",
        "    - Methodology clarity\n",
        "    - Result validation\n",
        "    - Contribution significance\n",
        "    - Logical flow\"\"\"\n",
        "\n",
        "    return justifier(prompt, max_length=200)[0]['generated_text']\n",
        "\n",
        "# Step 6: Process All Papers\n",
        "import pandas as pd\n",
        "\n",
        "results = []\n",
        "\n",
        "for idx, pdf_file in enumerate(os.listdir(papers_dir)):\n",
        "    if not pdf_file.endswith('.pdf'):\n",
        "        continue\n",
        "\n",
        "    pdf_path = os.path.join(papers_dir, pdf_file)\n",
        "    try:\n",
        "        paper_data = process_paper(pdf_path)\n",
        "        prediction = classify_paper(paper_data)\n",
        "        rationale = generate_rationale(paper_data, prediction)\n",
        "\n",
        "        results.append({\n",
        "            'Paper ID': f\"P{str(idx+1).zfill(3)}\",\n",
        "            'Publishable': prediction,\n",
        "            'Rationale': rationale\n",
        "        })\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_file}: {str(e)}\")\n",
        "\n",
        "# Step 7: Save Results\n",
        "df = pd.DataFrame(results)\n",
        "df.to_csv('/content/results.csv', index=False)\n",
        "print(\"Results saved to results.csv\")\n",
        "\n",
        "# Step 8: Evaluation (Using 15 Reference Papers)\n",
        "# Assuming first 15 papers are labeled\n",
        "reference_labels = [...]  # Add actual labels from problem statement\n",
        "\n",
        "if len(reference_labels) == 15:\n",
        "    from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "    y_true = reference_labels\n",
        "    y_pred = df['Publishable'].values[:15]\n",
        "\n",
        "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.2f}\")\n",
        "    print(f\"F1 Score: {f1_score(y_true, y_pred):.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "liCqPmhaF__L",
        "outputId": "0b47986b-85a5-4404-cb3f-93c74d88f14a"
      },
      "id": "liCqPmhaF__L",
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Requirement already satisfied: pymupdf in /usr/local/lib/python3.11/dist-packages (1.25.5)\n",
            "Requirement already satisfied: scipdf_parser in /usr/local/lib/python3.11/dist-packages (0.52)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.11/dist-packages (from scipdf_parser) (5.3.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from scipdf_parser) (2.32.3)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.11/dist-packages (from scipdf_parser) (3.8.5)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from scipdf_parser) (2.2.2)\n",
            "Requirement already satisfied: textstat in /usr/local/lib/python3.11/dist-packages (from scipdf_parser) (0.7.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->scipdf_parser) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->scipdf_parser) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->scipdf_parser) (2025.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->scipdf_parser) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->scipdf_parser) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->scipdf_parser) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->scipdf_parser) (2025.1.31)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (1.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (2.0.11)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (8.3.6)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (2.5.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (0.15.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (2.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (75.2.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy->scipdf_parser) (3.5.0)\n",
            "Requirement already satisfied: pyphen in /usr/local/lib/python3.11/dist-packages (from textstat->scipdf_parser) (0.17.2)\n",
            "Requirement already satisfied: cmudict in /usr/local/lib/python3.11/dist-packages (from textstat->scipdf_parser) (1.0.32)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy->scipdf_parser) (1.3.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->scipdf_parser) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->scipdf_parser) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->scipdf_parser) (0.4.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->scipdf_parser) (1.17.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->scipdf_parser) (1.3.0)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->scipdf_parser) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->scipdf_parser) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->scipdf_parser) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy->scipdf_parser) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->scipdf_parser) (0.21.0)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy->scipdf_parser) (7.1.0)\n",
            "Requirement already satisfied: importlib-metadata>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat->scipdf_parser) (8.6.1)\n",
            "Requirement already satisfied: importlib-resources>=5 in /usr/local/lib/python3.11/dist-packages (from cmudict->textstat->scipdf_parser) (6.5.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy->scipdf_parser) (3.0.2)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.11/dist-packages (from importlib-metadata>=5->cmudict->textstat->scipdf_parser) (3.21.0)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy->scipdf_parser) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->scipdf_parser) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->scipdf_parser) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy->scipdf_parser) (1.17.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy->scipdf_parser) (0.1.2)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/EARC Dataset-20250417T115257Z-0012.zip'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-98-b1ae2400aa47>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;31m# Extract only Papers folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Papers/'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.pdf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/EARC Dataset-20250417T115257Z-0012.zip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "# 1. Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# 2. Search for the ZIP file in My Drive (case-insensitive, partial match)\n",
        "search_term = \"EARC Dataset-20250417T115257Z-0012\"  # Change if your ZIP uses a different prefix\n",
        "zip_path = None\n",
        "for root, dirs, files in os.walk('/content/drive/My Drive'):\n",
        "    for file in files:\n",
        "        if file.lower().endswith('.zip') and search_term.lower() in file.lower():\n",
        "            zip_path = os.path.join(root, file)\n",
        "            break\n",
        "    if zip_path:\n",
        "        break\n",
        "\n",
        "if not zip_path:\n",
        "    raise FileNotFoundError(f\"Could not find a ZIP file containing '{search_term}' in its name in your Google Drive.\")\n",
        "\n",
        "print(f\"Found ZIP file: {zip_path}\")\n",
        "\n",
        "# 3. Extract only the Papers folder from the ZIP\n",
        "extract_path = '/content/extracted_papers'\n",
        "os.makedirs(extract_path, exist_ok=True)\n",
        "papers_folder = None\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    # Find all files in Papers/ and extract them\n",
        "    papers_files = [f for f in zip_ref.namelist() if f.startswith('Papers/') and f.endswith('.pdf')]\n",
        "    if not papers_files:\n",
        "        raise FileNotFoundError(\"No PDFs found in a 'Papers/' folder inside the ZIP.\")\n",
        "    for f in papers_files:\n",
        "        zip_ref.extract(f, extract_path)\n",
        "    papers_folder = os.path.join(extract_path, 'Papers')\n",
        "\n",
        "print(f\"Extracted {len(papers_files)} PDFs to {papers_folder}\")\n",
        "\n",
        "# 4. Process each PDF: print filename and first 500 characters as a test\n",
        "pdf_files = [f for f in os.listdir(papers_folder) if f.lower().endswith('.pdf')]\n",
        "if not pdf_files:\n",
        "    raise FileNotFoundError(f\"No PDFs found in extracted Papers folder: {papers_folder}\")\n",
        "\n",
        "for pdf_file in pdf_files:\n",
        "    pdf_path = os.path.join(papers_folder, pdf_file)\n",
        "    try:\n",
        "        with fitz.open(pdf_path) as doc:\n",
        "            text = \"\"\n",
        "            for page in doc:\n",
        "                text += page.get_text()\n",
        "            print(f\"\\n--- {pdf_file} ---\\n{text[:500]}\\n{'-'*40}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {pdf_file}: {e}\")\n",
        "\n",
        "print(f\"\\nProcessed {len(pdf_files)} PDFs successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "eRmfWqkvHJIs",
        "outputId": "e51dd0ad-6e10-48a0-91b3-0c10cd67473d"
      },
      "id": "eRmfWqkvHJIs",
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Could not find a ZIP file containing 'EARC Dataset-20250417T115257Z-0012' in its name in your Google Drive.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-101-ba18460c1320>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mzip_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not find a ZIP file containing '{search_term}' in its name in your Google Drive.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Found ZIP file: {zip_path}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Could not find a ZIP file containing 'EARC Dataset-20250417T115257Z-0012' in its name in your Google Drive."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kwXdNpjHbav",
        "outputId": "68a3d03a-4fde-4857-a22d-ec9135f10817"
      },
      "id": "2kwXdNpjHbav",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e1a9d9da3750457ab772780661db0de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_598783bca4be4280820d7f7e91d5c0ad",
              "IPY_MODEL_fe407353c1fd4f2d9e011eb62ace49ef",
              "IPY_MODEL_b40894b9da44499f83de99388516c7c6"
            ],
            "layout": "IPY_MODEL_441df1946ac24933a2cf09745a192b78"
          }
        },
        "598783bca4be4280820d7f7e91d5c0ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_80c7f19e4c0c4c23b32ab97a8fa34759",
            "placeholder": "​",
            "style": "IPY_MODEL_dd912d36cf3748fbbb87649e40281be7",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "fe407353c1fd4f2d9e011eb62ace49ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06b03ac76e8a4e28b5ffa5433f478d6a",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cb68d1536ce4d6bb0686fabae567a92",
            "value": 2
          }
        },
        "b40894b9da44499f83de99388516c7c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2902635410984d57ab77db517e0468ce",
            "placeholder": "​",
            "style": "IPY_MODEL_9425ca8831bd4ab78bacb0f4a3313928",
            "value": " 2/2 [01:30&lt;00:00, 42.02s/it]"
          }
        },
        "441df1946ac24933a2cf09745a192b78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80c7f19e4c0c4c23b32ab97a8fa34759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd912d36cf3748fbbb87649e40281be7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06b03ac76e8a4e28b5ffa5433f478d6a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cb68d1536ce4d6bb0686fabae567a92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2902635410984d57ab77db517e0468ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9425ca8831bd4ab78bacb0f4a3313928": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}